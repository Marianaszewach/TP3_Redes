{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Trabajo Práctico 3\n\nMariana Szewach - Camila Cirignoli - Amalia Oxandaberro","metadata":{}},{"cell_type":"markdown","source":"# Librerías","metadata":{}},{"cell_type":"markdown","source":"En primer lugar, se cargan todas las librerias a utilizar en el siguiente trabajo","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nfrom string import punctuation\nfrom termcolor import colored\nfrom collections import Counter\n!pip install UpSampling2D\nfrom tensorflow.keras.layers import Dense, Flatten, Conv2D, UpSampling2D, Dropout,BatchNormalization,GlobalAveragePooling2D, Activation, MaxPooling2D, AveragePooling2D, Input, Add\n\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.optimizers import SGD\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.optimizers import Nadam\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom sklearn.preprocessing import OneHotEncoder\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import plot_confusion_matrix\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import f1_score\n\nfrom tensorflow.keras.callbacks import TensorBoard\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping\nfrom keras.models import Model\n\nimport math, keras, datetime, pandas as pd, numpy as np, keras.backend as K\nimport matplotlib.pyplot as plt, operator, random, pickle\n!pip install utils2\nfrom utils2 import *\n!pip install pandas_summary\nfrom pandas_summary import DataFrameSummary\nfrom IPython.display import SVG\nfrom numpy import mean, sqrt, square, arange\nfrom keras.applications.vgg16 import VGG16\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.applications.resnet50 import ResNet50","metadata":{"execution":{"iopub.status.busy":"2021-11-28T17:16:33.458749Z","iopub.execute_input":"2021-11-28T17:16:33.459017Z","iopub.status.idle":"2021-11-28T17:16:50.306516Z","shell.execute_reply.started":"2021-11-28T17:16:33.458987Z","shell.execute_reply":"2021-11-28T17:16:50.305105Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"# Datos\n\nSe cargan los datos de la competencia","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-28T17:16:50.309249Z","iopub.execute_input":"2021-11-28T17:16:50.309541Z","iopub.status.idle":"2021-11-28T17:16:50.319753Z","shell.execute_reply.started":"2021-11-28T17:16:50.309501Z","shell.execute_reply":"2021-11-28T17:16:50.318346Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"x_train = np.load(\"../input/cnn-itba-2021-q2/X_train.npy\")\ny_train = np.load(\"../input/cnn-itba-2021-q2/y_train.npy\")\nx_test = np.load(\"../input/cnn-itba-2021-q2/X_test.npy\")","metadata":{"execution":{"iopub.status.busy":"2021-11-28T22:25:31.463270Z","iopub.execute_input":"2021-11-28T22:25:31.463552Z","iopub.status.idle":"2021-11-28T22:25:31.537995Z","shell.execute_reply.started":"2021-11-28T22:25:31.463522Z","shell.execute_reply":"2021-11-28T22:25:31.537224Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"# Pre procesamiento\nInicialmente, se separan los datos en train y valid para entrenar y validar el algoritmo respectivamente. Se dividieron los datos obteniendo un 80% para train y un 20% para valid. ","metadata":{}},{"cell_type":"code","source":"valid_porcentage = 0.2\nfrom sklearn.model_selection import train_test_split\nx_train, x_val, y_train, y_val = train_test_split(\n    x_train, y_train, test_size=valid_porcentage, random_state=42, stratify=y_train)\n","metadata":{"execution":{"iopub.status.busy":"2021-11-28T22:25:38.402772Z","iopub.execute_input":"2021-11-28T22:25:38.403223Z","iopub.status.idle":"2021-11-28T22:25:38.833241Z","shell.execute_reply.started":"2021-11-28T22:25:38.403178Z","shell.execute_reply":"2021-11-28T22:25:38.832439Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"A continuación se normalizan los datos para obtener valores entre 0 y 1. \nAdemás se generan los one-hot encoding para convertir las etiquetas de las clases a vectores de 0s y 1s.","metadata":{}},{"cell_type":"code","source":"x_train_norm = x_train/255\nx_val_norm = x_val/255\nx_test_norm = x_test/255\n\ny_train = to_categorical(y_train, num_classes = 100)\ny_val = to_categorical(y_val, num_classes = 100)","metadata":{"execution":{"iopub.status.busy":"2021-11-28T22:25:42.306552Z","iopub.execute_input":"2021-11-28T22:25:42.306810Z","iopub.status.idle":"2021-11-28T22:25:42.773809Z","shell.execute_reply.started":"2021-11-28T22:25:42.306775Z","shell.execute_reply":"2021-11-28T22:25:42.773076Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"# VGG\n\nA continuación se utiliza la red convolucional de 16 capas, VGG16 y se utiliza una versión pre-entrenada para la base de datos de imagenet.","metadata":{}},{"cell_type":"code","source":"modelVGG16 = VGG16(include_top = False, pooling = None, weights=\"imagenet\",input_shape=(32,32,3))","metadata":{"execution":{"iopub.status.busy":"2021-11-28T22:25:55.799016Z","iopub.execute_input":"2021-11-28T22:25:55.799730Z","iopub.status.idle":"2021-11-28T22:25:56.483132Z","shell.execute_reply.started":"2021-11-28T22:25:55.799693Z","shell.execute_reply":"2021-11-28T22:25:56.482331Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"for layer in modelVGG16.layers:\n    layer.trainable=False","metadata":{"execution":{"iopub.status.busy":"2021-11-28T22:25:58.445700Z","iopub.execute_input":"2021-11-28T22:25:58.446188Z","iopub.status.idle":"2021-11-28T22:25:58.451656Z","shell.execute_reply.started":"2021-11-28T22:25:58.446150Z","shell.execute_reply":"2021-11-28T22:25:58.450596Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"x_train_VGG16 = modelVGG16.predict(x_train_norm)\nx_valid_VGG16 = modelVGG16.predict(x_val_norm)","metadata":{"execution":{"iopub.status.busy":"2021-11-28T22:26:01.557802Z","iopub.execute_input":"2021-11-28T22:26:01.558158Z","iopub.status.idle":"2021-11-28T22:26:11.147965Z","shell.execute_reply.started":"2021-11-28T22:26:01.558121Z","shell.execute_reply":"2021-11-28T22:26:11.147190Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":"Se prosigue a armar el modelo con las capas que se pueden visualizar a continuación","metadata":{}},{"cell_type":"code","source":"input_preproc = Input(shape=(1,1,512))\n\nnet = Flatten()(input_preproc)\n\nnet = Dense(units=256, activation='relu')(net)\nnet = Dropout(0.2)(net)\n#net=Dense(units=256, activation='relu')(net)\n#net=Dropout(0.2)(net)\nnet = Dense(units=256, activation='relu')(net)\nnet = Dropout(0.2)(net)\nnet = Dense(units=100, activation = 'softmax')(net)\n\nmodel = Model(input_preproc,net)\n\nmodel.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2021-11-28T22:26:16.394489Z","iopub.execute_input":"2021-11-28T22:26:16.394749Z","iopub.status.idle":"2021-11-28T22:26:16.442051Z","shell.execute_reply.started":"2021-11-28T22:26:16.394720Z","shell.execute_reply":"2021-11-28T22:26:16.441351Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"#callbacks\ncheckpoint_file = 'checkpoint.VGG16.hdf5'\nearlystop = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=5, verbose=2)\ncheckpointer = ModelCheckpoint(monitor=\"val_accuracy\",filepath=checkpoint_file, verbose=1, save_best_only=True)","metadata":{"execution":{"iopub.status.busy":"2021-11-28T22:26:22.777441Z","iopub.execute_input":"2021-11-28T22:26:22.777695Z","iopub.status.idle":"2021-11-28T22:26:22.781903Z","shell.execute_reply.started":"2021-11-28T22:26:22.777667Z","shell.execute_reply":"2021-11-28T22:26:22.781259Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":"A continuación se entrena el modelo","metadata":{}},{"cell_type":"code","source":"batch_size = 64\nepocs = 100\n\nhistory = model.fit(x_train_VGG16, y_train,epochs = epocs, batch_size = batch_size, verbose = 1, \n        validation_data = (x_valid_VGG16, y_val), callbacks = [checkpointer, earlystop])","metadata":{"execution":{"iopub.status.busy":"2021-11-28T22:26:26.325162Z","iopub.execute_input":"2021-11-28T22:26:26.325942Z","iopub.status.idle":"2021-11-28T22:28:51.922747Z","shell.execute_reply.started":"2021-11-28T22:26:26.325897Z","shell.execute_reply":"2021-11-28T22:28:51.921990Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"f, (ax1, ax2) = plt.subplots(1, 2, sharex=True, figsize=(18,5))\nax1.plot(history.history['loss'], label=\"loss\")\nax1.plot(history.history['val_loss'], label=\"val_loss\")\nax1.legend()\n\nax2.plot(history.history['accuracy'], label=\"accuracy\")\nax2.plot(history.history['val_accuracy'], label=\"val_accuracy\")\nax2.legend()\nplt.show();","metadata":{"execution":{"iopub.status.busy":"2021-11-28T22:29:21.424910Z","iopub.execute_input":"2021-11-28T22:29:21.425485Z","iopub.status.idle":"2021-11-28T22:29:48.983018Z","shell.execute_reply.started":"2021-11-28T22:29:21.425445Z","shell.execute_reply":"2021-11-28T22:29:48.982310Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":"# VGG con pesos entrenables","metadata":{}},{"cell_type":"code","source":"model.load_weights('checkpoint.VGG16.hdf5')","metadata":{"execution":{"iopub.status.busy":"2021-11-28T22:30:10.704137Z","iopub.execute_input":"2021-11-28T22:30:10.704623Z","iopub.status.idle":"2021-11-28T22:30:10.720318Z","shell.execute_reply.started":"2021-11-28T22:30:10.704582Z","shell.execute_reply":"2021-11-28T22:30:10.719539Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"model_final_output = model(modelVGG16.output)\nmodel_final = Model(modelVGG16.input,model_final_output)\nmodel_final.summary()","metadata":{"execution":{"iopub.status.busy":"2021-11-28T22:30:13.880516Z","iopub.execute_input":"2021-11-28T22:30:13.880777Z","iopub.status.idle":"2021-11-28T22:30:13.916692Z","shell.execute_reply.started":"2021-11-28T22:30:13.880749Z","shell.execute_reply":"2021-11-28T22:30:13.915863Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"for layer in modelVGG16.layers:\n    layer.trainable=True","metadata":{"execution":{"iopub.status.busy":"2021-11-28T22:30:18.556684Z","iopub.execute_input":"2021-11-28T22:30:18.556975Z","iopub.status.idle":"2021-11-28T22:30:18.562744Z","shell.execute_reply.started":"2021-11-28T22:30:18.556943Z","shell.execute_reply":"2021-11-28T22:30:18.561884Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"model_final.compile(loss = 'categorical_crossentropy', optimizer = 'sgd', metrics = ['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2021-11-28T22:30:21.627876Z","iopub.execute_input":"2021-11-28T22:30:21.628145Z","iopub.status.idle":"2021-11-28T22:30:21.637796Z","shell.execute_reply.started":"2021-11-28T22:30:21.628114Z","shell.execute_reply":"2021-11-28T22:30:21.637081Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"#callbacks\ncheckpoint_file = 'checkpoint.VGG16_fine_tunning.hdf5'\nearlystop = EarlyStopping(monitor = 'val_accuracy', min_delta = 0, patience = 5, verbose = 2)\ncheckpointer = ModelCheckpoint(monitor = \"val_accuracy\",filepath = checkpoint_file, verbose = 1, save_best_only = True)","metadata":{"execution":{"iopub.status.busy":"2021-11-28T22:30:26.259280Z","iopub.execute_input":"2021-11-28T22:30:26.259537Z","iopub.status.idle":"2021-11-28T22:30:26.264572Z","shell.execute_reply.started":"2021-11-28T22:30:26.259508Z","shell.execute_reply":"2021-11-28T22:30:26.263103Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"batch_size = 64\nepocs = 100\n\nhistory = model_final.fit(x_train_norm, y_train, epochs = epocs, batch_size = batch_size, verbose = 1, \n        validation_data = (x_val_norm, y_val),callbacks = [checkpointer, earlystop])","metadata":{"execution":{"iopub.status.busy":"2021-11-28T22:30:28.582822Z","iopub.execute_input":"2021-11-28T22:30:28.583284Z","iopub.status.idle":"2021-11-28T22:35:30.968389Z","shell.execute_reply.started":"2021-11-28T22:30:28.583232Z","shell.execute_reply":"2021-11-28T22:35:30.967690Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"markdown","source":"# ResNet\nA continuación se utiliza ResNet 50, red convolucional de 50 capas y se utiliza una versión pre-entrenada para la base de datos de imagenet.\n\nLa utilización de redes convolucionales con pesos ya entrenados a partir de una base de datos similar se conoce como **transfer learning.**","metadata":{}},{"cell_type":"markdown","source":"En la siguiente celda se realiza la técnica de **data augmentation**. Cuando se cuenta con un número de imágenes pequeño, es posible aumentar el número modificando las imágenes originales (haciendo zoom,escalado, flip horizontal, etc).","metadata":{}},{"cell_type":"code","source":"train_datagen = ImageDataGenerator(rotation_range = 10,  zoom_range = 0.1, width_shift_range = 0.1,  \n        height_shift_range = 0.1, shear_range = 0.1, horizontal_flip = True,  vertical_flip = False)\ntrain_datagen.fit(x_train_norm)","metadata":{"execution":{"iopub.status.busy":"2021-11-28T17:16:51.255061Z","iopub.execute_input":"2021-11-28T17:16:51.255358Z","iopub.status.idle":"2021-11-28T17:16:51.622382Z","shell.execute_reply.started":"2021-11-28T17:16:51.255322Z","shell.execute_reply":"2021-11-28T17:16:51.621622Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"resnet_model = ResNet50(\n    include_top = False,\n    weights = 'imagenet',\n    input_shape = (224,224,3)\n)\n\nfor layer in resnet_model.layers:\n    if isinstance(layer, BatchNormalization):\n        layer.trainable = True\n    else:\n        layer.trainable = False","metadata":{"execution":{"iopub.status.busy":"2021-11-28T17:16:51.623693Z","iopub.execute_input":"2021-11-28T17:16:51.624056Z","iopub.status.idle":"2021-11-28T17:16:56.467642Z","shell.execute_reply.started":"2021-11-28T17:16:51.624007Z","shell.execute_reply":"2021-11-28T17:16:56.466805Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"Se arma el modelo de manera secuencial con las capas que se pueden observar a continuación:","metadata":{}},{"cell_type":"code","source":"modelRN=Sequential()\nmodelRN.add(UpSampling2D(size=(7, 7),interpolation='bilinear'))\nmodelRN.add(resnet_model)\nmodelRN.add(GlobalAveragePooling2D())\nmodelRN.add(Dropout(.25))\nmodelRN.add(Dense(256, activation='relu'))\nmodelRN.add(BatchNormalization())\nmodelRN.add(Dense(100, activation='softmax'))","metadata":{"execution":{"iopub.status.busy":"2021-11-28T17:16:56.468937Z","iopub.execute_input":"2021-11-28T17:16:56.469217Z","iopub.status.idle":"2021-11-28T17:16:56.496702Z","shell.execute_reply.started":"2021-11-28T17:16:56.469181Z","shell.execute_reply":"2021-11-28T17:16:56.495965Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"En la siguiente celda se utiliza el optimizador SGD y se compila el modelo (tarda mucho en correr)","metadata":{}},{"cell_type":"code","source":"optimizer = SGD(learning_rate=1e-3, momentum=0.9)\n\nmodelRN.compile(\n    optimizer = optimizer,\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)\n\nhistory=modelRN.fit(\n    train_datagen.flow(x_train_norm, y_train, batch_size = 128),\n    validation_data = (x_val_norm, y_val),\n    epochs = 100,\n    verbose = 1\n)","metadata":{"execution":{"iopub.status.busy":"2021-11-28T17:16:56.498095Z","iopub.execute_input":"2021-11-28T17:16:56.498542Z","iopub.status.idle":"2021-11-28T21:47:55.025899Z","shell.execute_reply.started":"2021-11-28T17:16:56.498504Z","shell.execute_reply":"2021-11-28T21:47:55.025166Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"A continuación se grafican los valores de **loss** y **val_loss** por un lado y **accuracy** y **val_accuracy** por otro, para comparar las progresiones de los distintos parámetros a lo largo del entrenamiento.","metadata":{}},{"cell_type":"code","source":"f, (ax1, ax2) = plt.subplots(1, 2, sharex=True, figsize=(18,5))\nax1.plot(history.history['loss'], label=\"loss\")\nax1.plot(history.history['val_loss'], label=\"val_loss\")\nax1.legend()\n\nax2.plot(history.history['accuracy'], label=\"accuracy\")\nax2.plot(history.history['val_accuracy'], label=\"val_accuracy\")\nax2.legend()\nplt.show();","metadata":{"execution":{"iopub.status.busy":"2021-11-28T21:49:59.150759Z","iopub.execute_input":"2021-11-28T21:49:59.151066Z","iopub.status.idle":"2021-11-28T21:49:59.508742Z","shell.execute_reply.started":"2021-11-28T21:49:59.151015Z","shell.execute_reply":"2021-11-28T21:49:59.508082Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"y_test_pred = modelRN.predict(x_test_norm)\ny_test_pred = y_test_pred.argmax(axis = 1)\ndf = pd.DataFrame(data = y_test_pred, columns = ['label'])\ndf.index.name = \"Id\"","metadata":{"execution":{"iopub.status.busy":"2021-11-28T21:50:29.739421Z","iopub.execute_input":"2021-11-28T21:50:29.740098Z","iopub.status.idle":"2021-11-28T21:50:50.503869Z","shell.execute_reply.started":"2021-11-28T21:50:29.740055Z","shell.execute_reply":"2021-11-28T21:50:50.503101Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"df.to_csv(\"submission.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-11-28T21:54:40.979418Z","iopub.execute_input":"2021-11-28T21:54:40.979696Z","iopub.status.idle":"2021-11-28T21:54:41.005385Z","shell.execute_reply.started":"2021-11-28T21:54:40.979666Z","shell.execute_reply":"2021-11-28T21:54:41.004630Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"from IPython.display import FileLink\nFileLink('submission.csv')","metadata":{"execution":{"iopub.status.busy":"2021-11-28T21:57:35.677863Z","iopub.execute_input":"2021-11-28T21:57:35.678143Z","iopub.status.idle":"2021-11-28T21:57:35.684131Z","shell.execute_reply.started":"2021-11-28T21:57:35.678113Z","shell.execute_reply":"2021-11-28T21:57:35.683110Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"# Conclusiones","metadata":{}},{"cell_type":"markdown","source":"En primer lugar, se utilizó una red convolucional de tipo VGG con transfer learning utilzando la red VGG16 con pesos preentrenados a partir  del dataset de imagenet y se congelaron dichos pesos. Con este modelo se obtuvo un accuracy de 0.3418 para el set de datos de validación.\n\nDado que el valor obtenido de accuracy era bajo, se probó utilizar el mismo modelo, pero esta vez entrenando\nlos pesos. Con este modelo se obtuvo un accuracy de 0.5735 para los datos de validación.\n\nPara ver si se obtenía un mejor modelo, se probó con una red convolucional de tipo Resnet con transfer\nlearning utilizando la red ResNet50 con pesos preentrenados a partir del dataset imagenet. Además dado que la cantidad de imagenes por clase era bastante reducida, se realizó data augmentation a los datos de train para tener una mayor cantidad de imágenes de entrada y así obtener un mejor entrenamiento del modelo. Con este modelo dentro de un modelo secuencial con otras capas se consiguió el mejor valor de accuracy de validación\nel cual fue 0.7484. Además, se comprobó que no hubiera mucho overfitting ya que el valor de accuracy para train era de 0.7983, por lo que se puede decir que el modelo generaliza bastante bien.","metadata":{}}]}